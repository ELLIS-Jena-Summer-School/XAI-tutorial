{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3a9563ed-feea-437e-8f34-f2cffd18a921",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-17T13:52:08.265440Z",
     "iopub.status.busy": "2025-08-17T13:52:08.264731Z",
     "iopub.status.idle": "2025-08-17T13:52:08.275911Z",
     "shell.execute_reply": "2025-08-17T13:52:08.274142Z",
     "shell.execute_reply.started": "2025-08-17T13:52:08.265380Z"
    }
   },
   "source": [
    "# Explainable AI for Earth Science: Practical Concepts, Workflows, and Pitfalls\n",
    "\n",
    "*ELLIS Summer School: AI for Earth and Climate Sciences, Jena (Germany), September 1–5, 2025*  \n",
    "\n",
    "https://github.com/ELLIS-Jena-Summer-School/XAI-tutorial\n",
    "\n",
    "**Prepared by:** Shijie Jiang (Max Planck Institute for Biogeochemistry)\n",
    "\n",
    "**Date:** 2025-09-02 \n",
    "\n",
    "**Reference**: Jiang, S., Sweet, L.-b., Blougouras, G., Brenning, A., Li, W., Reichstein, M., et al. (2024). How interpretable machine learning can benefit process understanding in the geosciences. Earth's Future, 12, e2024EF004540. https://doi.org/10.1029/2024EF004540\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58209ac0-5723-4743-818d-52678aa15e0e",
   "metadata": {},
   "source": [
    "This notebook is part of the hands-on tutorial for the summer school.  \n",
    "\n",
    "This tutorial introduces **explainable AI (XAI)** methods for machine learning models, with a focus on **time series data in geoscience**.  \n",
    "\n",
    "As a case study, we predict daily **Gross Primary Production (GPP)** from meteorological drivers such as **air temperature, shortwave radiation, precipitation, and vapor pressure deficit**. The goal is to understand how to explain its predictions.\n",
    "\n",
    "<img src=\"img/slide1.jpg\"/>\n",
    "\n",
    "Although the example centers on time series, the concepts extend to other data types such as **tabular data** and **images**.  \n",
    "\n",
    "The tutorial is structured in two parts:  \n",
    "\n",
    "1. **Workflow** – how to apply XAI methods (e.g., Integrated Gradients) to a time series prediction task, and how to interpret the outputs.  \n",
    "2. **Pitfalls** – common challenges in applying XAI to scientific problems, and strategies to avoid misinterpretation.  \n",
    "\n",
    "By the end, you will have a practical understanding of how XAI methods can be applied in geoscience, and what is required to use them correctly.  \n",
    "\n",
    "<img src=\"img/slide2.jpg\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a864648-0e5b-420a-9667-b50c0b60c55f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "import random\n",
    "import numpy as np\n",
    "from tqdm import trange\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "from captum.attr import Saliency, IntegratedGradients"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54a43304-13ba-4ad9-ac53-abb8cdd0d0a0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-17T13:55:48.877082Z",
     "iopub.status.busy": "2025-08-17T13:55:48.876367Z",
     "iopub.status.idle": "2025-08-17T13:55:48.891276Z",
     "shell.execute_reply": "2025-08-17T13:55:48.889508Z",
     "shell.execute_reply.started": "2025-08-17T13:55:48.877019Z"
    }
   },
   "source": [
    "# I. Workflow Overview\n",
    "\n",
    "In this tutorial we will follow a clear workflow for applying XAI to a time series prediction task:  \n",
    "\n",
    "**Build and train the model → Evaluate predictions → Apply XAI**\n",
    "\n",
    "**Problem Context**  \n",
    "> Gross Primary Production (**GPP**) is the total amount of carbon fixed by plants through photosynthesis.  \n",
    "> It is a central measure of ecosystem productivity and plays a key role in the global carbon cycle.  \n",
    ">   \n",
    "> Our goal in this case study is to **predict daily GPP** using a time series machine learning approach.  \n",
    "> Later, we will apply interpretability methods to examine what the model has learned.  \n",
    ">\n",
    "**Data**  \n",
    "> The dataset contains **real-world observations** of daily values from **2000-01-01 to 2019-12-31**.  \n",
    "> \n",
    "> Inputs (X): meteorological drivers of photosynthesis  \n",
    "> - **Air Temperature (°C)** – influences plant metabolic rates and photosynthetic efficiency  \n",
    "> - **Downward Shortwave Radiation (W/m2)** – sunlight energy available for photosynthesis  \n",
    "> - **Precipitation (mm/day)** – affects soil water availability for plant growth  \n",
    "> - **Vapour Pressure Deficit (kPa)** – indicator of atmospheric dryness; high values can limit water uptake and reduce carbon assimilation  \n",
    "> \n",
    "> Target (y): ecosystem carbon flux  \n",
    "> - **Gross Primary Production (gC/m2/day)** – rate at which vegetation absorbs carbon from the atmosphere  \n",
    ">\n",
    "**Why Time Series?**  \n",
    "> Photosynthesis depends not only on current conditions but also on the recent past.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "832c5113-e82b-4469-8bc4-72721d273b4c",
   "metadata": {},
   "source": [
    "## 1. Load and Inspect the Data\n",
    "\n",
    "We now load the dataset into a pandas DataFrame and take a first look at the variables and time span.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fd8e8ce-6b11-47c4-805e-30b3055d932d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load CSV with date as index\n",
    "path = \"xai_data.csv\"\n",
    "df = pd.read_csv(path, parse_dates=[\"date\"], index_col=\"date\")\n",
    "df = df.sort_index()\n",
    "\n",
    "# Select features and target\n",
    "feature_cols = [\"air_temp\", \"shortwave_rad\", \"precip\", \"vpd\"]\n",
    "target_col = \"gpp\"\n",
    "\n",
    "# Quick check\n",
    "print(f\"Data shape: {df.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaf5e443-6fec-4a5e-abcc-dff30a5a47d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Full descriptive names for titles\n",
    "full_names = {\n",
    "    \"air_temp\": \"Air Temperature\",\n",
    "    \"shortwave_rad\": \"Downward Shortwave Radiation\",\n",
    "    \"precip\": \"Precipitation\",\n",
    "    \"vpd\": \"Vapour Pressure Deficit\",\n",
    "    \"gpp\": \"Gross Primary Production\"\n",
    "}\n",
    "\n",
    "# Units\n",
    "units = {\n",
    "    \"air_temp\": \"°C\",\n",
    "    \"shortwave_rad\": \"W/m2\",\n",
    "    \"precip\": \"mm/day\",\n",
    "    \"vpd\": \"kPa\",\n",
    "    \"gpp\": \"gC/m2/day\"\n",
    "}\n",
    "\n",
    "vars_to_plot = feature_cols + [target_col]\n",
    "\n",
    "fig, axes = plt.subplots(len(vars_to_plot), 1, figsize=(8, 7), sharex=True)\n",
    "for ax, var in zip(axes, vars_to_plot):\n",
    "    df[var].plot(ax=ax, linewidth=1)\n",
    "    ax.set_title(f\"{full_names[var]} ({units[var]})\", fontsize=10, loc=\"left\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c4da9fc-73f9-43a1-aa04-230aeb6734bd",
   "metadata": {},
   "source": [
    "## 2. Prepare the Data\n",
    "\n",
    "We will train a sequence-to-one model: the input is the past 90 days of meteorological drivers including the current day, and the output is the GPP for that same day.\n",
    "\n",
    "First, we split the dataset into training, validation, and test periods based on years. This avoids data leakage from future to past.\n",
    "\n",
    "Feature scaling and target scaling are **fit on the training period only** and applied to validation/test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0868dcb8-e1e8-49c9-8506-d786282adea5",
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_len = 90  # number of days in each input sequence\n",
    "train_years = (2000, 2013)\n",
    "val_years   = (2014, 2016)\n",
    "test_years  = (2017, 2020)\n",
    "\n",
    "# Split by year\n",
    "df_train = df.loc[str(train_years[0]):str(train_years[1])]\n",
    "df_val   = df.loc[str(val_years[0]):str(val_years[1])]\n",
    "df_test  = df.loc[str(test_years[0]):str(test_years[1])]\n",
    "\n",
    "print(f\"Train: {len(df_train)}, Val: {len(df_val)}, Test: {len(df_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "441e2f9d-7176-469d-b0be-7498a2db60ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_scaler = StandardScaler().fit(df_train[feature_cols])\n",
    "y_scaler = StandardScaler().fit(df_train[[target_col]])\n",
    "\n",
    "def scale_df(df, X_scaler, y_scaler):\n",
    "    out = df.copy()\n",
    "    out[feature_cols] = X_scaler.transform(df[feature_cols])\n",
    "    out[target_col] = y_scaler.transform(df[[target_col]])\n",
    "    return out\n",
    "\n",
    "df_train_scaled = scale_df(df_train, X_scaler, y_scaler)\n",
    "df_val_scaled   = scale_df(df_val, X_scaler, y_scaler)\n",
    "df_test_scaled  = scale_df(df_test, X_scaler, y_scaler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aed0999b-1ab1-4807-9cbf-1c47a83ff6b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_sequences(data, seq_len, feature_cols, target_col):\n",
    "    X, y, dates = [], [], []\n",
    "    arr_X = data[feature_cols].values\n",
    "    arr_y = data[target_col].values\n",
    "    idx = data.index\n",
    "    for i in range(len(data) - seq_len + 1):\n",
    "        X.append(arr_X[i:i+seq_len])\n",
    "        y.append(arr_y[i+seq_len-1])    # same-day target\n",
    "        dates.append(idx[i+seq_len-1])  # date of target\n",
    "    return np.array(X), np.array(y), dates\n",
    "\n",
    "# Create sequences\n",
    "X_train, y_train, dates_train = create_sequences(df_train_scaled, seq_len, feature_cols, target_col)\n",
    "X_val,   y_val,   dates_val   = create_sequences(df_val_scaled, seq_len, feature_cols, target_col)\n",
    "X_test,  y_test,  dates_test  = create_sequences(df_test_scaled, seq_len, feature_cols, target_col)\n",
    "\n",
    "# Convert to tensors\n",
    "X_train_t = torch.tensor(X_train, dtype=torch.float32)\n",
    "y_train_t = torch.tensor(y_train, dtype=torch.float32).unsqueeze(-1)\n",
    "X_val_t   = torch.tensor(X_val, dtype=torch.float32)\n",
    "y_val_t   = torch.tensor(y_val, dtype=torch.float32).unsqueeze(-1)\n",
    "X_test_t  = torch.tensor(X_test, dtype=torch.float32)\n",
    "y_test_t  = torch.tensor(y_test, dtype=torch.float32).unsqueeze(-1)\n",
    "\n",
    "print(f\"Input shape:\\n  Train - {X_train_t.shape}\\n  Val   - {X_val_t.shape}\\n  Test  - {X_test_t.shape}\")\n",
    "print(f\"Target shape:\\n  Train - {y_train_t.shape}\\n  Val   - {y_val_t.shape}\\n  Test  - {y_test_t.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e097b5a3-80c8-4606-ba57-bba7e8d5c0e5",
   "metadata": {},
   "source": [
    "## 3. Define the Model\n",
    "\n",
    "We use a Long Short-Term Memory (**LSTM**) network for this task.\n",
    "\n",
    "- LSTMs are a type of recurrent neural network (RNN) designed to handle sequential data.\n",
    "- They can learn dependencies across time steps, making them well-suited for meteorological time series.\n",
    "- Our model takes 90 days of weather inputs and outputs a single GPP value for the last day.\n",
    "\n",
    "We use:\n",
    "- One LSTM layer\n",
    "- A fully connected output layer\n",
    "- Mean squared error loss\n",
    "- Adam optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "136ac82c-99bb-4993-b8de-e4831ddcd275",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Reproducibility ---\n",
    "def set_seed(seed=42):\n",
    "    import random, numpy as np\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "# --- Model ---\n",
    "class LSTMRegressor(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size=64, num_layers=1, dropout=0.0):\n",
    "        super().__init__()\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers,\n",
    "                            batch_first=True, dropout=dropout)\n",
    "        self.fc = nn.Linear(hidden_size, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out, _ = self.lstm(x)        # [B, T, H]\n",
    "        last = out[:, -1, :]         # last time step\n",
    "        yhat = self.fc(last)         # [B, 1]\n",
    "        return yhat\n",
    "\n",
    "# --- Init function ---\n",
    "def init_model(input_size, hidden_size=64, num_layers=1, dropout=0.0, seed=42, device=None):\n",
    "    set_seed(seed)\n",
    "    model = LSTMRegressor(input_size, hidden_size, num_layers, dropout)\n",
    "    if device is None:\n",
    "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    return model.to(device)\n",
    "\n",
    "# Example: initialize model\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = init_model(len(feature_cols), hidden_size=64, seed=42, device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7047a5c-e709-4955-b971-e3178d9ba633",
   "metadata": {},
   "source": [
    "## 4. Train the Model\n",
    "\n",
    "We train the LSTM using mini-batches and monitor performance on the validation set.\n",
    "We include:\n",
    "\n",
    "- **Early stopping**: stop training when validation loss does not improve for several epochs.\n",
    "- **Learning rate scheduling**: automatically reduce learning rate when validation loss plateaus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04fe0e3d-2759-4cbc-990c-6d533847b441",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_loader, val_loader, criterion, optimizer, scheduler,\n",
    "                device, max_epochs=30, patience=10):\n",
    "    best_val_loss = float('inf')\n",
    "    epochs_no_improve = 0\n",
    "    train_losses, val_losses = [], []\n",
    "\n",
    "    for epoch in trange(1, max_epochs+1, desc=\"Training\"):\n",
    "        # --- Training ---\n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "        for xb, yb in train_loader:\n",
    "            xb, yb = xb.to(device), yb.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            preds = model(xb)\n",
    "            loss = criterion(preds, yb)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss += loss.item() * xb.size(0)\n",
    "        train_loss /= len(train_loader.dataset)\n",
    "\n",
    "        # --- Validation ---\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        with torch.no_grad():\n",
    "            for xb, yb in val_loader:\n",
    "                xb, yb = xb.to(device), yb.to(device)\n",
    "                preds = model(xb)\n",
    "                loss = criterion(preds, yb)\n",
    "                val_loss += loss.item() * xb.size(0)\n",
    "        val_loss /= len(val_loader.dataset)\n",
    "\n",
    "        # Record\n",
    "        train_losses.append(train_loss)\n",
    "        val_losses.append(val_loss)\n",
    "\n",
    "        # Adjust LR\n",
    "        scheduler.step(val_loss)\n",
    "\n",
    "        # Early stopping\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            epochs_no_improve = 0\n",
    "            best_model_state = model.state_dict()\n",
    "        else:\n",
    "            epochs_no_improve += 1\n",
    "            if epochs_no_improve >= patience:\n",
    "                print(f\"\\nEarly stopping at epoch {epoch}\")\n",
    "                break\n",
    "\n",
    "    model.load_state_dict(best_model_state)\n",
    "    return model, train_losses, val_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "177d5b7f-6cf6-48ae-8d24-71d3cc80e36b",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "    optimizer, mode='min', factor=0.5, patience=3\n",
    ")\n",
    "\n",
    "# DataLoaders\n",
    "batch_size = 64\n",
    "train_loader = DataLoader(TensorDataset(X_train_t, y_train_t), batch_size=batch_size, shuffle=True)\n",
    "val_loader   = DataLoader(TensorDataset(X_val_t, y_val_t), batch_size=batch_size, shuffle=False)\n",
    "test_loader  = DataLoader(TensorDataset(X_test_t, y_test_t), batch_size=batch_size, shuffle=False)\n",
    "\n",
    "\n",
    "model, train_losses, val_losses = train_model(model, train_loader, val_loader, criterion, optimizer, scheduler, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e37155c2-f634-4219-aa06-3b1e74f6b992",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-16T20:32:56.130848Z",
     "iopub.status.busy": "2025-08-16T20:32:56.130575Z",
     "iopub.status.idle": "2025-08-16T20:32:56.133869Z",
     "shell.execute_reply": "2025-08-16T20:32:56.133418Z",
     "shell.execute_reply.started": "2025-08-16T20:32:56.130823Z"
    }
   },
   "source": [
    "## 5. Evaluate the Model\n",
    "\n",
    "We assess performance with the R2 score for training, validation, and test periods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94ce6117-e03c-4a5e-a213-a8de3d2bdd9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, X_t, y_t, dates, y_scaler):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        preds_scaled = model(X_t).cpu().numpy().ravel()\n",
    "    # inverse transform\n",
    "    preds = y_scaler.inverse_transform(preds_scaled.reshape(-1, 1)).ravel()\n",
    "    truth = y_scaler.inverse_transform(y_t.cpu().numpy().ravel().reshape(-1, 1)).ravel()\n",
    "    r2 = r2_score(truth, preds)\n",
    "    return r2, pd.Series(truth, index=dates), pd.Series(preds, index=dates)\n",
    "\n",
    "# Evaluate\n",
    "r2_train, y_true_train, y_pred_train = evaluate_model(model, X_train_t, y_train_t, dates_train, y_scaler)\n",
    "r2_val,   y_true_val,   y_pred_val   = evaluate_model(model, X_val_t, y_val_t, dates_val, y_scaler)\n",
    "r2_test,  y_true_test,  y_pred_test  = evaluate_model(model, X_test_t, y_test_t, dates_test, y_scaler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23a735af-4a08-4d96-bb69-977be7f23e13",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(12, 4))\n",
    "\n",
    "# Observed GPP for the whole period\n",
    "ax.plot(df.index, df[target_col], color=\"black\", linewidth=0.7, label=\"Observed\")\n",
    "\n",
    "# Predictions by split\n",
    "ax.plot(y_true_train.index, y_pred_train, color=\"tab:blue\", alpha=0.7, label=f\"Predicted (Train, R2={r2_train:.2f})\")\n",
    "ax.plot(y_true_val.index,   y_pred_val,   color=\"tab:orange\", alpha=0.7, label=f\"Predicted (Val, R2={r2_val:.2f})\")\n",
    "ax.plot(y_true_test.index,  y_pred_test,  color=\"tab:green\", alpha=0.7, label=f\"Predicted (Test, R2={r2_test:.2f})\")\n",
    "\n",
    "# Highlight test period\n",
    "ax.axvspan(y_true_test.index[0], y_true_test.index[-1], color=\"gray\", alpha=0.1)\n",
    "\n",
    "# Labels and title\n",
    "ax.set_title(\"Observed vs Predicted GPP\", fontsize=12)\n",
    "ax.set_ylabel(\"GPP (gC/m2/day)\")\n",
    "ax.set_xlabel(\"Date\")\n",
    "\n",
    "# Legend\n",
    "ax.legend(loc=\"lower left\", fontsize=10, frameon=False, ncol=4)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "236abf2e-08ed-4487-801a-314e806fba6f",
   "metadata": {},
   "source": [
    "## 6. Explaining the Model\n",
    "\n",
    "So far, we treated the LSTM as a **black box**: it takes 90 days of inputs and produces a GPP prediction.  \n",
    "But we have not asked *why* the model makes a certain prediction. Which drivers (e.g., radiation, precipitation, VPD) were most responsible? And which days in the 90-day window mattered most?\n",
    "\n",
    "To answer these questions, we use **Integrated Gradients (IG)**.\n",
    "\n",
    "IG is a method from explainable AI designed for neural networks.  \n",
    "The idea is:\n",
    "\n",
    "- We choose a **baseline input** (a reference with “no information”).  \n",
    "- We compare the model’s prediction on the actual input against its prediction on this baseline.  \n",
    "- IG attributes this difference to the individual input values  day by day, feature by feature.  \n",
    "\n",
    "The result is an attribution array with the same shape as the input sequence.  \n",
    "Each number tells us how much that particular feature on that particular day pushed the prediction up or down, relative to the baseline.\n",
    "\n",
    "This way, we can move from “the model predicts GPP = 5.2” to “this prediction was mainly driven by high radiation in the last week, partly offset by high VPD earlier in the window.”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19bd5253-eaf1-4a61-8766-5fe58075d1ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.dates as mdates\n",
    "\n",
    "def _date_cell_edges(dates):\n",
    "    \"\"\"Helper: compute left/right edges of each date cell for pcolormesh.\"\"\"\n",
    "    x = mdates.date2num(dates.to_pydatetime())  # centers\n",
    "    return np.concatenate(([x[0] - 0.5], (x[:-1] + x[1:]) / 2, [x[-1] + 0.5]))\n",
    "\n",
    "def plot_input_with_attribution(\n",
    "    df, dates_window,\n",
    "    input_seq, attribution_seq,\n",
    "    feature_names,\n",
    "    target_col=None, pred_value=None, obs_value=None,\n",
    "    baseline_pred_value=None, baseline_input_seq=None,\n",
    "    cmap=\"BrBG\", show_colorbar=True\n",
    "):\n",
    "    \"\"\"Plot drivers (features) with attributions as heatmaps.\n",
    "    If target_col / predictions are provided, adds a bottom panel for them.\n",
    "    \"\"\"\n",
    "\n",
    "    T, F = input_seq.shape\n",
    "    show_target_panel = target_col is not None and pred_value is not None and obs_value is not None\n",
    "\n",
    "    nrows = F + 1 if show_target_panel else F\n",
    "    fig, axes = plt.subplots(\n",
    "        nrows=nrows, ncols=1, figsize=(10, 6), sharex=True, gridspec_kw={'hspace': 0.4}\n",
    "    )\n",
    "\n",
    "    if nrows == 1:\n",
    "        axes = [axes]  # ensure iterable\n",
    "\n",
    "    vmax = np.quantile(np.abs(attribution_seq), 0.99) + 1e-8\n",
    "    x_edges = _date_cell_edges(dates_window)\n",
    "\n",
    "    # --- Feature panels ---\n",
    "    for i in range(F):\n",
    "        ax = axes[i]\n",
    "        z = attribution_seq[:, i][None, :]  # (1, T)\n",
    "        ymin, ymax = float(input_seq[:, i].min()), float(input_seq[:, i].max())\n",
    "        X = np.vstack([x_edges, x_edges])   # (2, T+1)\n",
    "        Y = np.vstack([np.full_like(x_edges, ymin), np.full_like(x_edges, ymax)])\n",
    "\n",
    "        pcm = ax.pcolormesh(X, Y, z, cmap=cmap, vmin=-vmax, vmax=vmax, shading=\"flat\")\n",
    "\n",
    "        # Overlay input series\n",
    "        ax.plot(dates_window, input_seq[:, i], color=\"black\", linewidth=1.2)\n",
    "        if baseline_input_seq is not None:\n",
    "            ax.plot(dates_window, baseline_input_seq[:, i],\n",
    "                    color=\"blue\", linewidth=1.0, alpha=0.9, label=\"Baseline input\")\n",
    "            if i == 0:\n",
    "                ax.legend(loc=\"center left\", fontsize=9, frameon=False, bbox_to_anchor=(1.0, 0.5))\n",
    "\n",
    "        # Title\n",
    "        varname = feature_names[i]\n",
    "        ax.set_title(f\"{full_names[varname]} ({units[varname]})\", fontsize=10, loc=\"left\")\n",
    "        ax.grid(True, linestyle=\"--\", alpha=0.3)\n",
    "\n",
    "    # --- Optional target panel ---\n",
    "    if show_target_panel:\n",
    "        ax = axes[-1]\n",
    "        ax.plot(dates_window, df.loc[dates_window, target_col],\n",
    "                color=\"black\", linewidth=1.4, label=\"Observed\")\n",
    "        ax.scatter(dates_window[-1], pred_value, color=\"red\", zorder=3, label=\"Pred (target)\")\n",
    "        if baseline_pred_value is not None:\n",
    "            ax.scatter(dates_window[-1], baseline_pred_value, color=\"blue\", zorder=3, label=\"Baseline pred\")\n",
    "        ax.set_title(f\"{full_names[target_col]} ({units[target_col]})\", fontsize=10, loc=\"left\")\n",
    "        ax.legend(fontsize=9, loc=\"lower left\", frameon=False, bbox_to_anchor=(1.0, -0.1))\n",
    "\n",
    "        # Date formatting\n",
    "        ax.xaxis.set_major_locator(mdates.AutoDateLocator())\n",
    "        ax.xaxis.set_major_formatter(mdates.ConciseDateFormatter(ax.xaxis.get_major_locator()))\n",
    "\n",
    "    # Shared colorbar\n",
    "    if show_colorbar:\n",
    "        fig.colorbar(pcm, ax=axes, orientation=\"vertical\", shrink=0.7, label=\"Attribution\")\n",
    "\n",
    "    return fig\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4a021d5-b3fc-4abc-a540-1eddb6128a77",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-17T13:02:39.469474Z",
     "iopub.status.busy": "2025-08-17T13:02:39.468803Z",
     "iopub.status.idle": "2025-08-17T13:02:39.480543Z",
     "shell.execute_reply": "2025-08-17T13:02:39.478549Z",
     "shell.execute_reply.started": "2025-08-17T13:02:39.469414Z"
    }
   },
   "source": [
    "### 6.1. A first look at IG on one sample\n",
    "\n",
    "We apply IG to one test sequence (90 days of inputs).  \n",
    "\n",
    "IG returns an **attribution array** with the same shape as the input: `[time steps, features]`.  \n",
    "Each entry shows how much a given feature on a given day contributed to the prediction:\n",
    "\n",
    "- Positive → pushed the prediction *up* (relative to baseline)  \n",
    "- Negative → pushed the prediction *down* (relative to baseline)  \n",
    "\n",
    "By design, the attributions add up to the prediction difference:\n",
    "\n",
    "$$\n",
    "\\text{Prediction} - \\text{Baseline prediction} \\;\\approx\\; \\sum_{t=1}^{T}\\sum_{f=1}^{F} \\mathrm{IG}_{t,f}\n",
    "$$\n",
    "\n",
    "A key part of IG is the **baseline**.  \n",
    "This is the input we use as a reference, i.e., the model’s prediction when “nothing informative” is given.  \n",
    "IG then attributes the change from this baseline prediction to the actual prediction.\n",
    "\n",
    "Here we use a **zero baseline**, which means all input features are set to zero in the standardized space.  \n",
    "Intuitively, this represents “neutral” conditions after scaling.  \n",
    "\n",
    "Later we will also test other baselines (e.g. climatology) to see how the choice of baseline affects the explanation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46f2bb61-2242-4e8e-b5ca-514b011e4c0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "ig = IntegratedGradients(model)\n",
    "\n",
    "# --- 1. Pick a sample ---\n",
    "idx = 150\n",
    "x = X_test_t[idx:idx+1]                     # input sequence [1, T, F]\n",
    "dates_win = df_test.index[idx:idx+seq_len]  # dates for the window\n",
    "\n",
    "# --- 2. Define the baseline ---\n",
    "# Here: all zeros in standardized space (we discuss baseline after seeing IG)\n",
    "baseline = torch.zeros_like(x)\n",
    "\n",
    "# --- 3. Compute attributions with IG ---\n",
    "attr, _ = ig.attribute(x, baselines=baseline, return_convergence_delta=True)\n",
    "attr = attr.squeeze(0).detach().cpu().numpy()   # shape [T, F]\n",
    "\n",
    "# --- 4. Predictions in scaled space ---\n",
    "with torch.no_grad():\n",
    "    pred_scaled = model(x).cpu().numpy().ravel()[0]       # model prediction\n",
    "    base_scaled = model(baseline).cpu().numpy().ravel()[0]# baseline prediction\n",
    "\n",
    "diff_scaled = pred_scaled - base_scaled   # difference explained by IG\n",
    "sum_attr = float(attr.sum())              # sum of all attributions\n",
    "comp_err = abs(diff_scaled - sum_attr)    # completeness check\n",
    "\n",
    "# --- 5. Convert to original units ---\n",
    "pred = y_scaler.inverse_transform([[pred_scaled]])[0,0]\n",
    "obs  = y_scaler.inverse_transform(y_test_t[idx:idx+1].cpu().numpy())[0,0]\n",
    "base = y_scaler.inverse_transform([[base_scaled]])[0,0]\n",
    "\n",
    "diff_unscaled = y_scaler.inverse_transform([[diff_scaled]])[0,0]\n",
    "sum_attr_unscaled = y_scaler.inverse_transform([[sum_attr]])[0,0]\n",
    "\n",
    "# --- 6. Print results ---\n",
    "print(f\"Sample index: {idx}  |  Window: {dates_win[0].date()} → {dates_win[-1].date()}\")\n",
    "print(f\"Observed GPP:          {obs:.3f} gC/m2/day\")\n",
    "print(f\"Model prediction:      {pred:.3f} gC/m2/day\")\n",
    "print(f\"Baseline prediction:   {base:.3f} gC/m2/day\")\n",
    "print()\n",
    "print(\"IG completeness check:\")\n",
    "print(f\"  Prediction − Baseline  = {diff_scaled:.5f} (scaled)  ≈  {diff_unscaled:.3f} (unscaled)\")\n",
    "print(f\"  Sum of IG attributions = {sum_attr:.5f} (scaled)  ≈  {sum_attr_unscaled:.3f} (unscaled)\")\n",
    "print(f\"  Error in equality      = {comp_err:.2e}\")\n",
    "print()\n",
    "print(f\"Attribution array shape: {attr.shape}  (time steps × features)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab712233-a1eb-432b-8f57-02cf72d33c03",
   "metadata": {},
   "source": [
    "### 6.2. Visualizing IG along inputs\n",
    "\n",
    "To better understand the attributions, we can overlay them directly on the input time series.  \n",
    "For each feature, the line shows the actual input values, while the background color shows the IG attribution:  \n",
    "\n",
    "- Green → this day’s input **increased** the prediction (relative to baseline)  \n",
    "- Brown → this day’s input **decreased** the prediction (relative to baseline)  \n",
    "\n",
    "The bottom panel shows the observed GPP, the model’s prediction, and the baseline prediction for the target day.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c8f9fd7-bd42-407f-b137-205790ecceb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plot_input_with_attribution(\n",
    "    df=df_test,                      # DataFrame slice\n",
    "    dates_window=dates_win,          # the 90-day window of dates\n",
    "    input_seq=X_scaler.inverse_transform(x.squeeze(0).cpu().numpy()),   # inputs in original units\n",
    "    attribution_seq=attr,            # IG attributions\n",
    "    feature_names=feature_cols,      # list of input names\n",
    "    target_col=target_col,           # \"gpp\"\n",
    "    pred_value=pred,\n",
    "    obs_value=obs,\n",
    "    baseline_pred_value=base,\n",
    "    baseline_input_seq=X_scaler.inverse_transform(baseline.squeeze(0).cpu().numpy()) # optional\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b570ba73-822b-4a0a-9fb2-87b6f40bfe01",
   "metadata": {},
   "source": [
    "### 6.3. Aggregating attributions: feature perspective  \n",
    "\n",
    "Because IG attributions are **additive**, we can aggregate them to see which features mattered most over the whole 90-day window.  \n",
    "\n",
    "Two useful summaries are:  \n",
    "\n",
    "- **Net contribution** (sum of IG values): shows whether a feature overall pushed the prediction *up* or *down*.  \n",
    "- **Mean absolute attribution** (importance): shows how strongly the model relied on a feature, regardless of direction.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04951e99-ed05-42bc-bad0-796083d9a3a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_signed = attr.sum(axis=0)       # net effect per feature\n",
    "feat_import = np.mean(np.abs(attr), axis=0)  # strength regardless of sign\n",
    "\n",
    "tbl = pd.DataFrame({\n",
    "    \"net_contribution\": feat_signed,\n",
    "    \"mean_abs_importance\": feat_import\n",
    "}, index=feature_cols)\n",
    "\n",
    "display(tbl.round(4))\n",
    "\n",
    "# --- Bar plots ---\n",
    "fig, ax = plt.subplots(1, 2, figsize=(10, 3), constrained_layout=True)\n",
    "\n",
    "ax[0].bar(feature_cols, feat_signed, color=\"tab:blue\")\n",
    "ax[0].axhline(0, color=\"black\", linewidth=0.8)\n",
    "ax[0].set_title(\"Net contribution (sum IG)\")\n",
    "ax[0].set_ylabel(\"IG (scaled output units)\")\n",
    "ax[0].tick_params(axis=\"x\", rotation=45)\n",
    "\n",
    "ax[1].bar(feature_cols, feat_import, color=\"tab:orange\")\n",
    "ax[1].set_title(\"Importance (mean |IG|)\")\n",
    "ax[1].set_ylabel(\"IG (scaled output units)\")\n",
    "ax[1].tick_params(axis=\"x\", rotation=45)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b8d0030-0312-497e-a9cb-fcfc9b3e1aa5",
   "metadata": {},
   "source": [
    "### 6.4. Aggregating attributions: time perspective  \n",
    "\n",
    "We can also summarize IG across features for each day.  \n",
    "This shows *when* in the 90-day window the model relied most on the inputs.  \n",
    "\n",
    "The result is a time series of daily importance values, highlighting which periods in the input sequence mattered most for this prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57858e79-1a14-4ebb-8a24-0cb7247e01b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggregate IG attributions over features → importance per time step\n",
    "time_import = np.mean(np.abs(attr), axis=1)   # length T (one value per day in the window)\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(10, 3))\n",
    "plt.plot(dates_win, time_import, color=\"darkred\")\n",
    "plt.ylabel(\"Mean |IG| across features\")\n",
    "plt.title(\"Per-day importance within the 90-day window\")\n",
    "\n",
    "ax = plt.gca()\n",
    "ax.xaxis.set_major_locator(mdates.AutoDateLocator())\n",
    "ax.xaxis.set_major_formatter(mdates.ConciseDateFormatter(ax.xaxis.get_major_locator()))\n",
    "plt.show()\n",
    "\n",
    "# Print top-5 most influential days\n",
    "topk = np.argsort(-time_import)[:5]\n",
    "print(\"Top-5 days by mean |IG|:\")\n",
    "for i in topk:\n",
    "    print(f\"  {dates_win[i].date()}   mean|IG|={time_import[i]:.5f}   signed_sum={attr[i].sum():.5f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b0fc120-a073-4a3b-be3d-41831af67c24",
   "metadata": {},
   "source": [
    "### 6.5. Comparing a high-GPP and a low-GPP day  \n",
    "\n",
    "To better understand what IG reveals, we compare two contrasting samples:  \n",
    "- one where the observed GPP is high,  \n",
    "- and one where the observed GPP is low.  \n",
    "\n",
    "By looking at the attribution patterns side by side, we can see how the model emphasizes different drivers depending on ecosystem activity.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4125bcd-ba8f-472f-8804-c0e5acbd772e",
   "metadata": {},
   "outputs": [],
   "source": [
    "high_idx = np.argmax(y_test_t.numpy())   # index of max GPP in test set\n",
    "low_idx  = np.argmin(y_test_t.numpy())   # index of min GPP in test set\n",
    "\n",
    "for idx, label in [(high_idx, \"High GPP sample\"), (low_idx, \"Low GPP sample\")]:\n",
    "    \n",
    "    # 1. Slice input and dates\n",
    "    x = X_test_t[idx:idx+1]\n",
    "    dates_win = df_test.index[idx:idx+seq_len]\n",
    "    baseline = torch.zeros_like(x)\n",
    "    \n",
    "    # 2. Compute IG\n",
    "    attr, _ = ig.attribute(x, baselines=baseline, return_convergence_delta=True)\n",
    "    attr = attr.squeeze(0).detach().cpu().numpy()\n",
    "    \n",
    "    # 3. Predictions\n",
    "    with torch.no_grad():\n",
    "        pred_scaled = model(x).cpu().numpy().ravel()[0]\n",
    "        base_scaled = model(baseline).cpu().numpy().ravel()[0]\n",
    "    pred = y_scaler.inverse_transform([[pred_scaled]])[0,0]\n",
    "    obs  = y_scaler.inverse_transform(y_test_t[idx:idx+1].cpu().numpy())[0,0]\n",
    "    base = y_scaler.inverse_transform([[base_scaled]])[0,0]\n",
    "\n",
    "    # 4. Plot with attribution overlay\n",
    "    fig = plot_input_with_attribution(\n",
    "        df=df_test,\n",
    "        dates_window=dates_win,\n",
    "        input_seq=X_scaler.inverse_transform(x.squeeze(0).numpy()),\n",
    "        attribution_seq=attr,\n",
    "        feature_names=feature_cols,\n",
    "        target_col=target_col,\n",
    "        pred_value=pred,\n",
    "        obs_value=obs,\n",
    "        baseline_pred_value=base,\n",
    "        baseline_input_seq=X_scaler.inverse_transform(baseline.squeeze(0).numpy())\n",
    "    )\n",
    "    fig.suptitle(f\"{label}\", fontsize=12)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2516bbb-e50d-42eb-93f7-508062262407",
   "metadata": {},
   "source": [
    "# II. Pitfalls and Good Practice in XAI\n",
    "\n",
    "Applying an explainability method is straightforward: a few lines of code give you attributions, heatmaps, or importance scores. \n",
    "But interpreting these results is the real challenge. In scientific applications like geoscience, careless use can lead to misleading or even wrong conclusions.\n",
    "\n",
    "Below we summarize several common pitfalls and points to keep in mind."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a81dc074-ae21-4fcc-8a85-f01447788f98",
   "metadata": {},
   "source": [
    "## 1. Baseline choice matters\n",
    "\n",
    "Integrated Gradients requires a **baseline** (or reference input).  \n",
    "All attributions are computed **relative to this baseline**.\n",
    "\n",
    "So far, we used a **zero baseline** (all inputs = 0 in standardized space).  \n",
    "This is convenient and ensures the math works — but it may not always be scientifically meaningful.\n",
    "\n",
    "Why does this matter?  \n",
    "- The baseline defines what the model’s *“no information”* state is.  \n",
    "- Changing the baseline can shift the interpretation of contributions.  \n",
    "- In geoscience, a zero input may not correspond to any realistic condition.  \n",
    "\n",
    "For example, we can compare two baselines for the same test sequence:  \n",
    "- Zero (all inputs = 0 after scaling)  \n",
    "- Climatology (the average seasonal cycle for each day of year)\n",
    "\n",
    "Different baselines yield different attributions, and both are valid in the sense of the IG framework, but their **scientific meaning** differs.  \n",
    "That’s why you must always document and reflect on your baseline choice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c23ede8-1d4a-4715-97ea-5697afdb0e8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 150\n",
    "x = X_test_t[idx:idx+1]\n",
    "dates_win = df_test.index[idx:idx+seq_len]\n",
    "\n",
    "# --- Zero baseline ---\n",
    "baseline_zero = torch.zeros_like(x)\n",
    "attr_zero, _ = ig.attribute(x, baselines=baseline_zero, return_convergence_delta=True)\n",
    "attr_zero = attr_zero.squeeze(0).detach().cpu().numpy()\n",
    "\n",
    "with torch.no_grad():\n",
    "    pred_scaled = model(x).cpu().numpy().ravel()[0]\n",
    "    base_zero_scaled = model(baseline_zero).cpu().numpy().ravel()[0]\n",
    "pred = y_scaler.inverse_transform([[pred_scaled]])[0,0]\n",
    "obs  = y_scaler.inverse_transform(y_test_t[idx:idx+1].cpu().numpy())[0,0]\n",
    "base_zero = y_scaler.inverse_transform([[base_zero_scaled]])[0,0]\n",
    "\n",
    "fig = plot_input_with_attribution(\n",
    "    df=df_test,\n",
    "    dates_window=dates_win,\n",
    "    input_seq=X_scaler.inverse_transform(x.squeeze(0).numpy()),\n",
    "    attribution_seq=attr_zero,\n",
    "    feature_names=feature_cols,\n",
    "    target_col=target_col,\n",
    "    pred_value=pred,\n",
    "    obs_value=obs,\n",
    "    baseline_pred_value=base_zero,\n",
    "    baseline_input_seq=X_scaler.inverse_transform(baseline_zero.squeeze(0).numpy())\n",
    ")\n",
    "fig.suptitle(f\"Sample (idx = {idx}): IG with Zero Baseline\", fontsize=12)\n",
    "\n",
    "# --- Climatology baseline ---\n",
    "clim_values = df_train.groupby(df_train.index.dayofyear).mean()\n",
    "clim_seq = clim_values.loc[dates_win.dayofyear, feature_cols]\n",
    "baseline_clim = torch.tensor(\n",
    "    X_scaler.transform(clim_seq),  # preserves DataFrame with feature names\n",
    "    dtype=torch.float32\n",
    ").unsqueeze(0)\n",
    "\n",
    "attr_clim, _ = ig.attribute(x, baselines=baseline_clim, return_convergence_delta=True)\n",
    "attr_clim = attr_clim.squeeze(0).detach().cpu().numpy()\n",
    "\n",
    "with torch.no_grad():\n",
    "    base_clim_scaled = model(baseline_clim).cpu().numpy().ravel()[0]\n",
    "base_clim = y_scaler.inverse_transform([[base_clim_scaled]])[0,0]\n",
    "\n",
    "fig = plot_input_with_attribution(\n",
    "    df=df_test,\n",
    "    dates_window=dates_win,\n",
    "    input_seq=X_scaler.inverse_transform(x.squeeze(0).numpy()),\n",
    "    attribution_seq=attr_clim,\n",
    "    feature_names=feature_cols,\n",
    "    target_col=target_col,\n",
    "    pred_value=pred,\n",
    "    obs_value=obs,\n",
    "    baseline_pred_value=base_clim,\n",
    "    baseline_input_seq=X_scaler.inverse_transform(baseline_clim.squeeze(0).numpy())\n",
    ")\n",
    "fig.suptitle(f\"Sample (idx = {idx}): IG with Climatology Baseline\", fontsize=12)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbc89526-e1bf-4010-9934-842c7e42c3a5",
   "metadata": {},
   "source": [
    "Notice how the attribution patterns differ between the two baselines.  \n",
    "With the zero baseline, certain inputs appear strongly influential, while with the climatology baseline their contribution is weaker or even changes sign.  \n",
    "\n",
    "The key message:  \n",
    "**Integrated Gradients explains predictions relative to the chosen baseline. Interpret results only in that context. An inappropriate baseline can shift the story and lead to misleading conclusions.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6acedd1a-3c77-4011-9c21-d50bd169b992",
   "metadata": {},
   "source": [
    "## 2. Attribution method choice matters\n",
    "\n",
    "Different attribution methods can give different results on the same sample.  \n",
    "This is expected: each method has its own assumptions and sensitivity.\n",
    "\n",
    "As good practice, it is worth checking at least two methods.  \n",
    "If they give consistent signals, confidence in the interpretation increases.  \n",
    "If they differ, it shows the explanation is method-dependent and should be treated with caution.\n",
    "\n",
    "Here we compare **Integrated Gradients** with a simple **Saliency map**.\n",
    "\n",
    "- **Saliency** computes the gradient of the output with respect to the input.  \n",
    "  It tells us which small local changes in the input would most affect the prediction.  \n",
    "  Saliency does *not* use a baseline.\n",
    "\n",
    "- **Integrated Gradients** accumulates gradients along a path from a baseline input to the actual input.  \n",
    "  It distributes the difference between baseline prediction and actual prediction across all input values.  \n",
    "  IG therefore requires a baseline, and the attributions are additive by design."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75e76743-e0fe-457d-9ae5-531903dbfd0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 150\n",
    "x = X_test_t[idx:idx+1]\n",
    "dates_win = df_test.index[idx:idx+seq_len]\n",
    "\n",
    "# --- IG attributions (baseline = zero) ---\n",
    "ig = IntegratedGradients(model)\n",
    "attr_ig, _ = ig.attribute(x, baselines=torch.zeros_like(x), return_convergence_delta=True)\n",
    "attr_ig = attr_ig.squeeze(0).detach().cpu().numpy()\n",
    "\n",
    "# --- Saliency attributions ---\n",
    "sal = Saliency(model)\n",
    "attr_sal = sal.attribute(x, abs=False)\n",
    "attr_sal = attr_sal.squeeze(0).detach().cpu().numpy()\n",
    "\n",
    "# --- Plot IG (inputs only) ---\n",
    "fig = plot_input_with_attribution(\n",
    "    df=df_test,\n",
    "    dates_window=dates_win,\n",
    "    input_seq=X_scaler.inverse_transform(x.squeeze(0).numpy()),\n",
    "    attribution_seq=attr_ig,\n",
    "    feature_names=feature_cols,\n",
    "    show_colorbar=True\n",
    ")\n",
    "fig.suptitle(f\"Sample (idx = {idx}): Integrated Gradients\", fontsize=12)\n",
    "plt.show()\n",
    "\n",
    "# --- Plot Saliency (inputs only) ---\n",
    "fig = plot_input_with_attribution(\n",
    "    df=df_test,\n",
    "    dates_window=dates_win,\n",
    "    input_seq=X_scaler.inverse_transform(x.squeeze(0).numpy()),\n",
    "    attribution_seq=attr_sal,\n",
    "    feature_names=feature_cols,\n",
    "    show_colorbar=True\n",
    ")\n",
    "fig.suptitle(f\"Sample (idx = {idx}): Saliency\", fontsize=12)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22340c7f-d280-4146-ac08-0949fb8e264f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-17T15:06:34.878965Z",
     "iopub.status.busy": "2025-08-17T15:06:34.878296Z",
     "iopub.status.idle": "2025-08-17T15:06:34.885478Z",
     "shell.execute_reply": "2025-08-17T15:06:34.883956Z",
     "shell.execute_reply.started": "2025-08-17T15:06:34.878903Z"
    }
   },
   "source": [
    "Notice the difference. Which view is more useful depends on the question:  \n",
    "\n",
    "- If your question is *“What parts of this input sequence most contributed to the prediction compared to a reference state?”* → IG is more suitable.  \n",
    "- If your question is *“Where is the model most sensitive to small perturbations right now?”* → Saliency is appropriate.  \n",
    "\n",
    "**Key message:** explanations are **method-dependent**.  \n",
    "Always state which method you used and how it matches the scientific question.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6acdd661-f4fe-4ede-9448-40c0924473ff",
   "metadata": {},
   "source": [
    "## 3. Explanations reflect the model, not the true process  \n",
    "\n",
    "XAI methods explain how *this model* makes predictions, not how the real-world system works.  \n",
    "\n",
    "To see this, we can remove an important driver (temperature) and retrain the model.  \n",
    "If predictive performance remains acceptable, the attributions will still “explain” the new model, but those explanations may differ, because the model has changed.  \n",
    "\n",
    "This shows that interpretability is always tied to the specific model you trained,  \n",
    "not a guarantee of causal understanding of the system.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83b7214a-246d-4d1e-b25a-b4dd01bcb6bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Drop one feature: Air Temperature ---\n",
    "drop_feature = \"air_temp\"\n",
    "keep_features = [f for f in feature_cols if f != drop_feature]\n",
    "keep_idx = [i for i, f in enumerate(feature_cols) if f != drop_feature]\n",
    "\n",
    "# Directly subset tensors (already windowed)\n",
    "X_train_red = X_train_t[:, :, keep_idx]\n",
    "X_val_red   = X_val_t[:, :, keep_idx]\n",
    "X_test_red  = X_test_t[:, :, keep_idx]\n",
    "\n",
    "y_train_red, y_val_red, y_test_red = y_train_t, y_val_t, y_test_t\n",
    "\n",
    "# --- Fit scaler on reduced features (for inverse_transform later) ---\n",
    "X_scaler_red = StandardScaler().fit(df_train[keep_features].values)\n",
    "\n",
    "# --- Train a new model with reduced features ---\n",
    "model_red = init_model(len(keep_features), hidden_size=64, seed=42, device=device)\n",
    "\n",
    "train_loader_red = DataLoader(TensorDataset(X_train_red, y_train_red), batch_size=batch_size, shuffle=True)\n",
    "val_loader_red   = DataLoader(TensorDataset(X_val_red, y_val_red), batch_size=batch_size, shuffle=False)\n",
    "test_loader_red  = DataLoader(TensorDataset(X_test_red, y_test_red), batch_size=batch_size, shuffle=False)\n",
    "\n",
    "optimizer = torch.optim.Adam(model_red.parameters(), lr=1e-3)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "    optimizer, mode='min', factor=0.5, patience=3\n",
    ")\n",
    "\n",
    "model_red, train_losses_red, val_losses_red = train_model(\n",
    "    model_red, train_loader_red, val_loader_red,\n",
    "    criterion, optimizer, scheduler, device\n",
    ")\n",
    "\n",
    "# --- Evaluate ---\n",
    "r2_train_red, y_true_train_red, y_pred_train_red = evaluate_model(model_red, X_train_red, y_train_red, dates_train, y_scaler)\n",
    "r2_val_red,   y_true_val_red,   y_pred_val_red   = evaluate_model(model_red, X_val_red, y_val_red, dates_val, y_scaler)\n",
    "r2_test_red,  y_true_test_red,  y_pred_test_red  = evaluate_model(model_red, X_test_red, y_test_red, dates_test, y_scaler)\n",
    "\n",
    "print(f\"Full model R2 (test): {r2_test:.3f}\")\n",
    "print(f\"Reduced model R2 (test, without {drop_feature}): {r2_test_red:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "163a8955-f8b2-41b6-a20b-9cd05f311f33",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 120\n",
    "x_full = X_test_t[idx:idx+1]\n",
    "x_red  = X_test_red[idx:idx+1]\n",
    "dates_win = df_test.index[idx:idx+seq_len]\n",
    "\n",
    "# ---------------- FULL MODEL ----------------\n",
    "ig_full = IntegratedGradients(model)\n",
    "attr_full, _ = ig_full.attribute(\n",
    "    x_full.to(device),\n",
    "    baselines=torch.zeros_like(x_full).to(device),\n",
    "    return_convergence_delta=True\n",
    ")\n",
    "attr_full = attr_full.squeeze(0).detach().cpu().numpy()\n",
    "\n",
    "with torch.no_grad():\n",
    "    pred_scaled = model(x_full.to(device)).cpu().numpy().ravel()[0]\n",
    "    base_scaled = model(torch.zeros_like(x_full).to(device)).cpu().numpy().ravel()[0]\n",
    "\n",
    "pred_full = y_scaler.inverse_transform([[pred_scaled]])[0,0]\n",
    "obs_full  = y_scaler.inverse_transform(y_test_t[idx:idx+1].cpu().numpy())[0,0]\n",
    "base_full = y_scaler.inverse_transform([[base_scaled]])[0,0]\n",
    "\n",
    "fig = plot_input_with_attribution(\n",
    "    df=df_test,\n",
    "    dates_window=dates_win,\n",
    "    input_seq=X_scaler.inverse_transform(x_full.squeeze(0).cpu().numpy()),\n",
    "    attribution_seq=attr_full,\n",
    "    feature_names=feature_cols,\n",
    "    target_col=target_col,\n",
    "    pred_value=pred_full,\n",
    "    obs_value=obs_full,\n",
    "    baseline_pred_value=base_full,\n",
    "    baseline_input_seq=X_scaler.inverse_transform(torch.zeros_like(x_full).squeeze(0).cpu().numpy())\n",
    ")\n",
    "fig.suptitle(f\"Full model (idx={idx}): IG attributions\", fontsize=12)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# ---------------- REDUCED MODEL ----------------\n",
    "ig_red = IntegratedGradients(model_red)\n",
    "attr_red, _ = ig_red.attribute(\n",
    "    x_red.to(device),\n",
    "    baselines=torch.zeros_like(x_red).to(device),\n",
    "    return_convergence_delta=True\n",
    ")\n",
    "attr_red = attr_red.squeeze(0).detach().cpu().numpy()\n",
    "\n",
    "with torch.no_grad():\n",
    "    pred_scaled_red = model_red(x_red.to(device)).cpu().numpy().ravel()[0]\n",
    "    base_scaled_red = model_red(torch.zeros_like(x_red).to(device)).cpu().numpy().ravel()[0]\n",
    "\n",
    "pred_red = y_scaler.inverse_transform([[pred_scaled_red]])[0,0]\n",
    "obs_red  = y_scaler.inverse_transform(y_test_red[idx:idx+1].cpu().numpy())[0,0]\n",
    "base_red = y_scaler.inverse_transform([[base_scaled_red]])[0,0]\n",
    "\n",
    "X_scaler_red = StandardScaler().fit(\n",
    "    df_train[keep_features].values.reshape(-1, len(keep_features))\n",
    ")\n",
    "\n",
    "fig = plot_input_with_attribution(\n",
    "    df=df_test,\n",
    "    dates_window=dates_win,\n",
    "    input_seq=X_scaler_red.inverse_transform(x_red.squeeze(0).cpu().numpy()),\n",
    "    attribution_seq=attr_red,\n",
    "    feature_names=keep_features,\n",
    "    target_col=target_col,\n",
    "    pred_value=pred_red,\n",
    "    obs_value=obs_red,\n",
    "    baseline_pred_value=base_red,\n",
    "    baseline_input_seq=X_scaler_red.inverse_transform(torch.zeros_like(x_red).squeeze(0).cpu().numpy())\n",
    ")\n",
    "fig.suptitle(f\"Reduced model (idx={idx}, without {drop_feature}): IG attributions\", fontsize=12)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a4813cf-e4e5-498f-a422-0071e1baad48",
   "metadata": {},
   "source": [
    "Notice how the attributions change when we retrain the model without *Air Temperature*.  \n",
    "\n",
    "Even when predictive performance remains similar, the attribution patterns can shift considerably.  \n",
    "This illustrates a key principle: XAI methods explain **how the model makes predictions, not how the real system works**.  \n",
    "When an important driver is missing, the model redistributes importance to the remaining inputs, especially those that are correlated.  \n",
    "\n",
    "Interpretability results should therefore always be understood in the context of the model’s design and available features.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "231ab6ee-070a-4650-aeec-0fb5cd0e83d3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-17T20:28:32.797312Z",
     "iopub.status.busy": "2025-08-17T20:28:32.796626Z",
     "iopub.status.idle": "2025-08-17T20:28:32.807879Z",
     "shell.execute_reply": "2025-08-17T20:28:32.806101Z",
     "shell.execute_reply.started": "2025-08-17T20:28:32.797252Z"
    }
   },
   "source": [
    "## 4. Explanations depend on model randomness\n",
    "\n",
    "Neural networks are trained with random initialization and stochastic optimization.  \n",
    "Even with the same data and hyperparameters, changing the random seed can produce models with similar predictive accuracy but different attribution patterns.  \n",
    "\n",
    "This means that explanations also carry uncertainty: they reflect *this particular trained model*, not a guaranteed truth about the data.  \n",
    "For more robust insights, check whether attribution patterns are consistent across multiple training runs.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "832a2ce0-7953-4a4c-a68a-8b6eef42e7c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "seeds = [42, 5555]\n",
    "attributions = []\n",
    "\n",
    "idx = 150\n",
    "x = X_test_t[idx:idx+1]\n",
    "dates_win = df_test.index[idx:idx+seq_len]\n",
    "\n",
    "for seed in seeds:\n",
    "    # --- Train a fresh model with a different seed ---\n",
    "    model_seed = init_model(len(feature_cols), hidden_size=64, seed=seed, device=device)\n",
    "    optimizer = torch.optim.Adam(model_seed.parameters(), lr=1e-3)\n",
    "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=3)\n",
    "    \n",
    "    train_loader = DataLoader(TensorDataset(X_train_t, y_train_t), batch_size=64, shuffle=True)\n",
    "    val_loader   = DataLoader(TensorDataset(X_val_t, y_val_t), batch_size=64, shuffle=False)\n",
    "    \n",
    "    model_seed, _, _ = train_model(\n",
    "        model_seed, train_loader, val_loader,\n",
    "        criterion, optimizer, scheduler, device, \n",
    "    )\n",
    "    \n",
    "    # --- Attribution (IG) ---\n",
    "    ig = IntegratedGradients(model_seed)\n",
    "    attr, _ = ig.attribute(\n",
    "        x.to(device),\n",
    "        baselines=torch.zeros_like(x).to(device),\n",
    "        return_convergence_delta=True\n",
    "    )\n",
    "    attributions.append(attr.squeeze(0).detach().cpu().numpy())\n",
    "    \n",
    "    # --- Prediction ---\n",
    "    with torch.no_grad():\n",
    "        pred_scaled = model_seed(x.to(device)).cpu().numpy().ravel()[0]\n",
    "    pred = y_scaler.inverse_transform([[pred_scaled]])[0,0]\n",
    "    obs  = y_scaler.inverse_transform(y_test_t[idx:idx+1].cpu().numpy())[0,0]\n",
    "    \n",
    "    # --- Plot ---\n",
    "    fig = plot_input_with_attribution(\n",
    "        df=df_test,\n",
    "        dates_window=dates_win,\n",
    "        input_seq=X_scaler.inverse_transform(x.squeeze(0).cpu().numpy()),\n",
    "        attribution_seq=attributions[-1],\n",
    "        feature_names=feature_cols,\n",
    "        target_col=target_col,\n",
    "        pred_value=pred,\n",
    "        obs_value=obs,\n",
    "        baseline_pred_value=None,\n",
    "        baseline_input_seq=None\n",
    "    )\n",
    "    fig.suptitle(f\"Seed {seed}: IG attributions (idx={idx})\", fontsize=12)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07f332af-31a0-4fb7-b11b-732e841f9bdf",
   "metadata": {},
   "source": [
    "As a result, attribution maps may vary across runs, even when predictive accuracy is stable.  \n",
    "\n",
    "**Good practice:**  \n",
    "- Train models with multiple random seeds and compare explanations for consistency.  \n",
    "- Repeat analyses with different data splits to see whether patterns hold.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71b6e1fb-dbc1-4d03-abc9-0b351b588e68",
   "metadata": {},
   "source": [
    "<img src=\"img/slide3.jpg\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ba811d5-f7fb-46ad-bd4b-410e4e6a7404",
   "metadata": {},
   "source": [
    "If you want to learn more about when, where, and how XAI can be used to understand processes in Earth and climate research, refer to Jiang et al. (2024). \n",
    "\n",
    "Jiang, S., Sweet, L.-b., Blougouras, G., Brenning, A., Li, W., Reichstein, M., et al. (2024). How interpretable machine learning can benefit process understanding in the geosciences. Earth's Future, 12, e2024EF004540. https://doi.org/10.1029/2024EF004540"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
